\subsection{Design Goals}

We want to provide an architecture for web data processing that is based on unified treatment of data on annotation and processing side
and that allows the backend machinery to access all information contained in a web page, including how it is presented to a web surfer.

\subsection{Requirements}

\begin{description}

\item[Flexibility]
The system should be open enough to allow customization of every part, but also specifically provide stable interfaces for more common tasks to allow for modularization.

\item[Stability]
We need a stable http data source that is independent of the original website, including any dependencies such as images, stylesheets or scripts.

\item[Automaticity]
Backend processing should run without requiring any kind of human interaction.

\item[Replicability]
Computations carried out on web pages' representation must be replicable accross systems, including any user-side processing.

\item[Quantity]
Corpus size should not influence the performance of the system and total processing time should grow linearly with the corpus.

\item[Usability]
Usability of the annotators side is of paramount importance, so we should stay as close as possible to the everyday web experience.
We also need to provide tools for learning how to use the annotation tool and how to annotate web pages.

\end{description}

\subsection{Core Architecture}

To address these requirements, we developed an abstract architecture, a simplified version of which is depicted in figure \ref{f:arch}.
We will outline the rationale for the basic design decisions below.


For rendering a web page, an object tree is constructed from its HTML source code.
This tree can be traversed and its nodes inspected, modified, deleted and created through an API specified by the World Wide Web Consortium's (W3C) DOM Standard \cite{dom}.
It's most popular use case is client-side dynamic manipulation of web pages, for visual effects and interactivity.
This is most commonly done by accessing the DOM through a JavaScript interpreter.
Essentially, a page's DOM tree allows access to all the information we set out to work on: structure, textual content and visual rendering data.
We therefore make it the sole interface between application and data.

While all browsers try to implement some part of the DOM standard (currently, version 3 is only partially implemented in most popular browsers), they vary greatly in their level of compliance as well as their ability to cope with non-standard compliant content.
This leads to structural and visual differences between different browsers rendering the same web page.

Therefore, to guarantee replicability, we require the same DOM engine to be used through the system.


To reach a maximal level of automaticity, it is important that data processing can take place in a parallel fashion and does not require any kind of graphical interface, so it can be executed on server farms.
On the other hand we also need to be able to present pages within a browser to allow for user annotation.
Consequently, the same DOM engine needs to power a browser as well as a headless back-end application.




\begin{figure}
\jss{\includegraphics[width=0.5\textwidth]{arch}}
	{\includegraphics[width=\textwidth]{arch}}
\caption{\label{f:arch}Simplified \KrdWrd architecture: both users annotating corpus pages through their web browser
and back-end applications working on the data share storage and DOM engine.}
\end{figure}


\subsection{Modules}

shared data source for addon and app, http controller for addon.
